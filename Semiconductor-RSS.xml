<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Semiconductor Recap News</title>
    <link>https://github.com/EdsonBellido/semiconductor-RSS</link>
    <description>Articles for semiconductor professionals</description>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Dec 2025 01:00:20 GMT</lastBuildDate>
    <atom:link rel="hub" href="http://pubsubhubbub.appspot.com/" />
    <atom:link href="https://raw.githack.com/EdsonBellido/semiconductor-RSS/main/Semiconductor-RSS.xml" rel="self" type="application/rss+xml" />

    <item>
      <title>Ensuring Accuracy in LLM-Generated Hardware Logic Design Automation (IBM Research)</title>
      <link>https://semiengineering.com/ensuring-accuracy-in-llm-generated-hardware-logic-design-automation-ibm-research/</link>
      <description>&lt;p&gt;&lt;img src=&quot;https://semiengineering.com/wp-content/uploads/iStock-1441278907-11-29-23.jpeg&quot; alt=&quot;iStock-1441278907-11-29-23.jpeg&quot;&gt;&lt;/p&gt;&lt;p&gt;A new technical paper “Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation” was published by researchers at IBM Research.&lt;/p&gt;  
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;  
&lt;p&gt;“We show for invertible problems that transform data from a source domain (for example, Logic Condition Tables (LCTs)) to a destination domain (for example, Hardware Description Language (HDL) code), an approach of using Large Language Models (LLMs) as a lossless encoder from source to destination followed by as a lossless decoder back to the source, comparable to lossless compression in information theory, can mitigate most of the LLM drawbacks of hallucinations and omissions. Specifically, using LCTs as inputs, we generate the full HDL for a two-dimensional network-on-chip router (13 units, 1500-2000 lines of code) using seven different LLMs, reconstruct the LCTs from the auto-generated HDL, and compare the original and reconstructed LCTs. This approach yields significant productivity improvements, not only confirming correctly generated LLM logic and detecting incorrectly generated LLM logic but also assisting developers in finding design specification errors.”&lt;/p&gt;  
&lt;p&gt;Find the technical &lt;a href=&quot;https://arxiv.org/abs/2512.03053&quot;&gt;paper here&lt;/a&gt;.  November 2025.&lt;/p&gt;  
&lt;p&gt;Cassidy, Andrew S., Guillaume Garreau, Jay Sivagnaname, Mike Grassi, Bernard Brezzo, John V. Arthur, and Dharmendra S. Modha. “Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation.” arXiv preprint arXiv:2512.03053 (2025).&lt;/p&gt;  
&lt;p&gt;The post &lt;a href=&quot;https://semiengineering.com/ensuring-accuracy-in-llm-generated-hardware-logic-design-automation-ibm-research/&quot;&gt;Ensuring Accuracy in LLM-Generated Hardware Logic Design Automation (IBM Research)&lt;/a&gt; appeared first on &lt;a href=&quot;https://semiengineering.com&quot;&gt;Semiconductor Engineering&lt;/a&gt;.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://semiengineering.com/ensuring-accuracy-in-llm-generated-hardware-logic-design-automation-ibm-research/</guid>
      <pubDate>Tue, 09 Dec 2025 00:32:02 GMT</pubDate>
    </item>
  </channel>
</rss>